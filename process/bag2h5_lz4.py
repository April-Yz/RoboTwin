#!/usr/bin/env python3
"""
High Performance ROS bag to HDF5 Converter (Pure Python Version)
Features:
1. Native LZ4/ZSTD support (via 'rosbags' lib).
2. Resizes all images to 640x480.
3. Parallel Processing for image decoding.

python3 bag2h5_lz4.py /projects/zaijia001/R1/pour/pour_0201 --batch --workers 8 --output /projects/zaijia001/R1/h5/pour/pour_0201
python3 bag2h5_lz4.py /projects/zaijia001/R1/pour/pour_0202 --batch --workers 8 --output /projects/zaijia001/R1/h5/pour/pour_0202
python3 bag2h5_lz4.py /projects/zaijia001/R1/pour/pour_0203 --batch --workers 8 --output /projects/zaijia001/R1/h5/pour/pour_0203
python3 bag2h5_lz4.py /projects/zaijia001/R1/pour/pour_0203_1 --batch --workers 8 --output /projects/zaijia001/R1/h5/pour/pour_0203_1
python3 bag2h5_lz4.py /projects/zaijia001/R1/pick --batch --workers 8 --output /projects/zaijia001/R1/h5/pick
"""

import h5py
import numpy as np
import cv2
from pathlib import Path
from tqdm import tqdm
import argparse
from scipy.interpolate import interp1d
from concurrent.futures import ProcessPoolExecutor, as_completed
import time
import bisect

# --- 引入 rosbags 库 (替代 rosbag) ---
try:
    from rosbags.rosbag1 import Reader
    from rosbags.typesys import get_typestore, Stores
except ImportError:
    print("Error: Library 'rosbags' not found.")
    print("Please run: pip install rosbags")
    exit(1)

# --- 目标分辨率设置 ---
TARGET_WIDTH = 640
TARGET_HEIGHT = 480

# --- 全局解码函数 (必须在主作用域) ---

def decode_depth_chunk(args):
    """解码深度图并 Resize 到 640x480"""
    raw_bytes_list, width, height, encoding = args
    decoded_list = []
    
    # 确定数据类型
    if '16UC1' in encoding or 'mono16' in encoding:
        dtype = np.uint16
        n_channels = 1
    elif '32FC1' in encoding:
        dtype = np.float32
        n_channels = 1
    elif '8UC1' in encoding or 'mono8' in encoding:
        dtype = np.uint8
        n_channels = 1
    else:
        dtype = np.uint16
        n_channels = 1

    for data in raw_bytes_list:
        if data is None:
            decoded_list.append(np.zeros((TARGET_HEIGHT, TARGET_WIDTH), dtype=dtype))
            continue
            
        # 注意: rosbags 传来的 data 可能是 memoryview，需要转为 bytes 或直接读取
        img = np.frombuffer(data, dtype=dtype)
        try:
            # 1. 还原原始形状
            if n_channels == 1:
                img = img.reshape(height, width)
            else:
                img = img.reshape(height, width, n_channels)
            
            # 2. Resize (关键：深度图必须用最近邻插值)
            if width != TARGET_WIDTH or height != TARGET_HEIGHT:
                img = cv2.resize(img, (TARGET_WIDTH, TARGET_HEIGHT), interpolation=cv2.INTER_NEAREST)
                
            decoded_list.append(img)
        except ValueError:
            decoded_list.append(np.zeros((TARGET_HEIGHT, TARGET_WIDTH), dtype=dtype))
            
    return decoded_list

def decode_rgb_chunk(bytes_list):
    """解码 RGB 并 Resize 到 640x480"""
    decoded_list = []
    for data in bytes_list:
        if data is None:
            decoded_list.append(np.zeros((TARGET_HEIGHT, TARGET_WIDTH, 3), dtype=np.uint8)) 
            continue
            
        np_arr = np.frombuffer(data, np.uint8)
        img_bgr = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        
        if img_bgr is not None:
            # 1. Resize (RGB图用线性插值)
            if img_bgr.shape[1] != TARGET_WIDTH or img_bgr.shape[0] != TARGET_HEIGHT:
                img_bgr = cv2.resize(img_bgr, (TARGET_WIDTH, TARGET_HEIGHT), interpolation=cv2.INTER_LINEAR)
            
            # 2. 转 RGB
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            decoded_list.append(img_rgb)
        else:
            decoded_list.append(None)
    return decoded_list

# --- 辅助函数 ---

def get_nearest_index(timestamps, target_time):
    idx = bisect.bisect_left(timestamps, target_time)
    if idx == 0: return 0
    if idx == len(timestamps): return len(timestamps) - 1
    before = timestamps[idx - 1]
    after = timestamps[idx]
    if after - target_time < target_time - before: return idx
    else: return idx - 1

# --- 核心转换逻辑 ---

def bag_to_h5(bag_path, output_path, num_workers=4):
    bag_path = Path(bag_path)
    print(f"\n>>> Processing: {bag_path.name}")
    print(f"    Output: {output_path}")
    
    start_time = time.time()

    # 1. READ PHASE
    raw_data = {
        'camera_head_rgb': [], 'camera_head_depth': [],
        'camera_left_rgb': [], 'camera_left_depth': [],
        'camera_right_rgb': [], 'camera_right_depth': [],
    }
    meta = {
        'head_w': 640, 'head_h': 480, 'head_enc': '16UC1',
        'left_w': 640, 'left_h': 480, 'left_enc': '16UC1',
        'right_w': 640, 'right_h': 480, 'right_enc': '16UC1'
    }
    num_data = {
        'arm_left_pos': [], 'arm_right_pos': [],
        'gripper_left_pos': [], 'gripper_right_pos': [],
        'action_arm_left_pos': [], 'action_arm_right_pos': [],
        'action_gripper_left_pos_cmd': [], 'action_gripper_right_pos_cmd': []
    }
    timestamps = {k: [] for k in list(raw_data.keys()) + list(num_data.keys())}
    
    # 映射 topic 到内部 key (高频版本优先，_low后缀为降频备选)
    topic_map_priority = {
        'camera_head_rgb': ['/hdas/camera_head/rgb/image_rect_color/compressed'],
        'camera_head_depth': ['/hdas/camera_head/depth/depth_registered'],
        'camera_left_rgb': ['/left/camera/color/image_raw/compressed'],
        'camera_left_depth': ['/left/camera/depth/image_rect_raw'],
        'camera_right_rgb': ['/right/camera/color/image_raw/compressed'],
        'camera_right_depth': ['/right/camera/depth/image_rect_raw'],
        'arm_left_pos': ['/hdas/feedback_arm_left', '/hdas/feedback_arm_left_low'],
        'arm_right_pos': ['/hdas/feedback_arm_right', '/hdas/feedback_arm_right_low'],
        'gripper_left_pos': ['/hdas/feedback_gripper_left', '/hdas/feedback_gripper_left_low'],
        'gripper_right_pos': ['/hdas/feedback_gripper_right', '/hdas/feedback_gripper_right_low'],
        'action_arm_left_pos': ['/motion_target/target_joint_state_arm_left', '/motion_target/target_joint_state_arm_left_low'],
        'action_arm_right_pos': ['/motion_target/target_joint_state_arm_right', '/motion_target/target_joint_state_arm_right_low'],
        'action_gripper_left_pos_cmd': ['/motion_control/position_control_gripper_left', '/motion_control/position_control_gripper_left_low'],
        'action_gripper_right_pos_cmd': ['/motion_control/position_control_gripper_right', '/motion_control/position_control_gripper_right_low']
    }
    
    # 初始化 rosbags 类型系统
    typestore = get_typestore(Stores.ROS1_NOETIC)

    try:
        with Reader(bag_path) as reader:
            # 获取 bag 中实际存在的所有 topics
            available_topics = {conn.topic for conn in reader.connections}
            
            # 根据优先级选择实际使用的 topic
            topic_map = {}  # 最终使用的 topic -> key 映射
            used_topics_info = {}  # 记录每个 key 使用的是哪个 topic
            
            for key, topic_candidates in topic_map_priority.items():
                for topic in topic_candidates:
                    if topic in available_topics:
                        topic_map[topic] = key
                        used_topics_info[key] = topic
                        break
            
            # 打印使用的 topics 信息
            print("    Topic selection:")
            for key in sorted(used_topics_info.keys()):
                topic = used_topics_info[key]
                is_low = '_low' in topic
                freq_info = " [LOW FREQ]" if is_low else " [HIGH FREQ]"
                print(f"      {key:30s} <- {topic}{freq_info}")
            print()
            # 筛选出我们需要读取的 connection
            connections = [x for x in reader.connections if x.topic in topic_map]
            total_msgs = sum(1 for _ in reader.messages(connections=connections))
            
            print("    [1/4] Reading bag (Unpacking)...")
            
            # 重置生成器开始读取
            msg_gen = reader.messages(connections=connections)
            
            with tqdm(total=total_msgs, leave=False) as pbar:
                for connection, timestamp, rawdata in msg_gen:
                    key = topic_map[connection.topic]
                    t_sec = timestamp * 1e-9  # rosbags 时间戳是纳秒
                    
                    # 反序列化消息
                    msg = typestore.deserialize_ros1(rawdata, connection.msgtype)

                    # --- 处理图像数据 (RGB Compressed) ---
                    if 'compressed' in connection.topic:
                        # CompressedImage: data 已经是 jpg/png 字节流
                        raw_data[key].append(msg.data)
                        timestamps[key].append(t_sec)
                    
                    # --- 处理深度图 (Image) ---
                    elif 'depth' in connection.topic:
                        # Image: data 是 raw bytes
                        raw_data[key].append(msg.data)
                        timestamps[key].append(t_sec)
                        # 更新 meta 信息 (假设同一种 topic 格式一致)
                        prefix = key.split('_')[1] # head, left, right
                        meta[f'{prefix}_enc'] = msg.encoding
                        meta[f'{prefix}_h'] = msg.height
                        meta[f'{prefix}_w'] = msg.width

                    # --- 处理数值数据 ---
                    elif 'joint_state' in connection.topic or 'feedback' in connection.topic:
                        # JointState 类型的消息，取 position
                        if hasattr(msg, 'position'):
                            num_data[key].append(np.array(msg.position, dtype=np.float64))
                            timestamps[key].append(t_sec)
                            
                    elif 'position_control' in connection.topic:
                        # Int16/Float 类型的命令数据
                        if hasattr(msg, 'data'):
                             num_data[key].append(msg.data)
                             timestamps[key].append(t_sec)

                    pbar.update(1)

    except Exception as e:
        print(f"Error reading bag: {e}")
        import traceback
        traceback.print_exc()
        return False

    # 2. ALIGNMENT
    print("    [2/4] Aligning timestamps (15Hz)...")
    all_ts = []
    for k in timestamps:
        if timestamps[k]: all_ts.extend(timestamps[k])
    
    if not all_ts:
        print("    Error: No timestamps found.")
        return False

    TARGET_FPS = 15
    t_start, t_end = min(all_ts), max(all_ts)
    duration = t_end - t_start
    num_samples = int(duration * TARGET_FPS)
    if num_samples < 1: num_samples = 1
    
    uniform_timeline = np.linspace(t_start, t_end, num_samples)
    aligned_data = {'timestamps': uniform_timeline}

    # Interpolate Numerical (降采样到15Hz)
    def interp_numerical(key):
        ts = np.array(timestamps[key])
        vals = np.array(num_data[key])
        if len(ts) == 0: return None
        if len(ts) == 1: 
            # Handle scalar or array
            if vals.ndim == 1: # list of scalars -> 1D array
                return np.repeat(vals[0], num_samples)
            else: # list of arrays -> 2D array
                return np.repeat(vals[0][np.newaxis, :], num_samples, axis=0)
        
        # 频率计算
        freq = len(ts) / (ts[-1] - ts[0]) if len(ts) > 1 else 0
        
        # 处理可能的标量列表转numpy
        if vals.ndim == 1: # scalar data stream
             kind = 'nearest' if freq > 100 else 'linear'
             f = interp1d(ts, vals, kind=kind, fill_value="extrapolate")
             return f(uniform_timeline)
        else: # array data stream (joint positions)
             kind = 'nearest' if freq > 100 else 'linear'
             f = interp1d(ts, vals, axis=0, kind=kind, bounds_error=False, fill_value=(vals[0], vals[-1]))
             return f(uniform_timeline)

    aligned_data['obs_arm_left_pos'] = interp_numerical('arm_left_pos')
    aligned_data['obs_arm_right_pos'] = interp_numerical('arm_right_pos')
    aligned_data['obs_gripper_left_pos'] = interp_numerical('gripper_left_pos')
    aligned_data['obs_gripper_right_pos'] = interp_numerical('gripper_right_pos')
    aligned_data['action_arm_left_pos'] = interp_numerical('action_arm_left_pos')
    aligned_data['action_arm_right_pos'] = interp_numerical('action_arm_right_pos')
    aligned_data['action_gripper_left_cmd'] = interp_numerical('action_gripper_left_pos_cmd')
    aligned_data['action_gripper_right_cmd'] = interp_numerical('action_gripper_right_pos_cmd')

    def compute_gripper_action(obs):
        if obs is None: return None
        # 简单的逻辑: 保持除最后一维外的维度，最后一维做特殊处理
        # 假设 obs 是 (N, 1) 或者 (N,)
        if obs.ndim == 1:
            action = obs.copy()
        else:
            action = obs.copy() # Placeholder
            
        # 复刻原逻辑: where(action > 50, action, action * 0.9)
        action = np.where(action > 50, action, action * 0.9)
        return action

    aligned_data['action_gripper_left_pos'] = compute_gripper_action(aligned_data['obs_gripper_left_pos'])
    aligned_data['action_gripper_right_pos'] = compute_gripper_action(aligned_data['obs_gripper_right_pos'])

    # 3. DECODING
    print(f"    [3/4] Decoding & Resizing images ({num_workers} workers)...")
    
    def get_selected_bytes(key):
        ts_list = timestamps[key]
        data_list = raw_data[key]
        if not ts_list: return []
        # 使用 bisect 查找最近帧的原始 bytes
        return [data_list[get_nearest_index(ts_list, t)] for t in uniform_timeline]

    rgb_keys = ['camera_head_rgb', 'camera_left_rgb', 'camera_right_rgb']
    depth_keys = ['camera_head_depth', 'camera_left_depth', 'camera_right_depth']
    
    # 只有当 key 存在数据时才提交任务
    valid_rgb_keys = [k for k in rgb_keys if timestamps[k]]
    valid_depth_keys = [k for k in depth_keys if timestamps[k]]

    executor = ProcessPoolExecutor(max_workers=num_workers)
    futures = {}

    for key in valid_rgb_keys:
        bytes_list = get_selected_bytes(key)
        chunk_size = len(bytes_list) // num_workers + 1
        for i in range(0, len(bytes_list), chunk_size):
            chunk = bytes_list[i:i + chunk_size]
            futures[executor.submit(decode_rgb_chunk, chunk)] = (key, i)

    for key in valid_depth_keys:
        bytes_list = get_selected_bytes(key)
        prefix = key.split('_')[1]
        args = (bytes_list, meta[f'{prefix}_w'], meta[f'{prefix}_h'], meta[f'{prefix}_enc'])
        
        chunk_size = len(bytes_list) // num_workers + 1
        for i in range(0, len(bytes_list), chunk_size):
            chunk_bytes = bytes_list[i:i + chunk_size]
            chunk_args = (chunk_bytes, args[1], args[2], args[3])
            futures[executor.submit(decode_depth_chunk, chunk_args)] = (key, i)

    # Initialize lists in aligned_data
    for key in valid_rgb_keys + valid_depth_keys:
        aligned_data['obs_' + key] = [None] * num_samples

    with tqdm(total=len(futures), leave=False) as pbar:
        for future in as_completed(futures):
            key, start_idx = futures[future]
            try:
                decoded_chunk = future.result()
                final_key = 'obs_' + key
                for j, img in enumerate(decoded_chunk):
                    if start_idx + j < num_samples:
                        aligned_data[final_key][start_idx + j] = img
            except Exception as e:
                print(f"    Error decoding {key}: {e}")
            pbar.update(1)
    
    executor.shutdown()

    # To Numpy
    for key in valid_rgb_keys + valid_depth_keys:
        obs_key = 'obs_' + key
        if obs_key in aligned_data and aligned_data[obs_key] is not None:
             valid = [img for img in aligned_data[obs_key] if img is not None]
             if valid: aligned_data[obs_key] = np.array(valid)
             else: del aligned_data[obs_key]

    # 4. SAVE
    print(f"    [4/4] Saving to HDF5...")
    with h5py.File(output_path, 'w') as f:
        f.create_dataset('timestamps', data=aligned_data['timestamps'])
        obs_group = f.create_group('obs')
        action_group = f.create_group('action')

        def save_ds(group, name, data, compress=False):
            if data is None or len(data) == 0: return
            if compress: group.create_dataset(name, data=data, compression='gzip', compression_opts=4)
            else: group.create_dataset(name, data=data)

        for cam in ['head', 'left', 'right']:
            save_ds(obs_group, f'camera_{cam}/rgb', aligned_data.get(f'obs_camera_{cam}_rgb'), True)
            save_ds(obs_group, f'camera_{cam}/depth', aligned_data.get(f'obs_camera_{cam}_depth'), True)

        for side in ['left', 'right']:
            save_ds(obs_group, f'arm_{side}/joint_pos', aligned_data.get(f'obs_arm_{side}_pos'))
            save_ds(obs_group, f'gripper_{side}/joint_pos', aligned_data.get(f'obs_gripper_{side}_pos'))
            save_ds(action_group, f'arm_{side}/joint_pos', aligned_data.get(f'action_arm_{side}_pos'))
            save_ds(action_group, f'gripper_{side}/joint_pos', aligned_data.get(f'action_gripper_{side}_pos'))
            
            if aligned_data.get(f'action_gripper_{side}_cmd') is not None:
                save_ds(action_group, f'gripper_{side}/commanded_pos', aligned_data[f'action_gripper_{side}_cmd'])

        f.attrs['source_bag'] = str(bag_path.name)
        f.attrs['fps'] = TARGET_FPS
        f.attrs['duration'] = duration

    elapsed = time.time() - start_time
    print(f"    Done! Time: {elapsed/60:.2f} min, Size: {output_path.stat().st_size / 1024**3:.2f} GB")
    return True

# --- 批量处理逻辑 ---

def batch_process(input_path, output_path, workers):
    input_path = Path(input_path)
    output_path = Path(output_path)
    output_path.mkdir(parents=True, exist_ok=True)
    
    bag_files = sorted(list(input_path.glob("*.bag")))
    # 过滤掉 fixed_ 文件
    bag_files = [f for f in bag_files if not f.name.startswith('fixed_')]
    
    print(f"Found {len(bag_files)} bag files in {input_path}")
    
    success_count = 0
    for i, bag_file in enumerate(bag_files):
        h5_name = bag_file.with_suffix('.h5').name
        h5_path = output_path / h5_name
        
        print(f"\n[{i+1}/{len(bag_files)}] Starting conversion...")
        if h5_path.exists():
            print(f"    Skipping {h5_name} (Already exists)")
            success_count += 1
            continue
            
        if bag_to_h5(bag_file, h5_path, workers):
            success_count += 1
            
    print(f"\nBatch processing complete! Converted {success_count}/{len(bag_files)} files.")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Batch convert ROS bags to resized HDF5 (Native LZ4 Support)')
    parser.add_argument('input', type=str, help='Input directory or file')
    parser.add_argument('--output', '-o', type=str, required=True, help='Output directory or file')
    parser.add_argument('--workers', '-w', type=int, default=4, help='Number of CPU workers per file')
    parser.add_argument('--batch', '-b', action='store_true', help='Enable batch directory processing')
    
    args = parser.parse_args()
    input_path = Path(args.input)
    
    is_dir = input_path.is_dir() or args.batch
    
    if is_dir:
        batch_process(args.input, args.output, args.workers)
    else:
        output_file = Path(args.output)
        if output_file.suffix == '' or output_file.is_dir():
            output_file.mkdir(parents=True, exist_ok=True)
            output_file = output_file / input_path.with_suffix('.h5').name
        bag_to_h5(input_path, output_file, args.workers)